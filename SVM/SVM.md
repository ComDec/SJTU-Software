# SVM实操

## 1.介绍
一个分类任务通常包括将数据分离成**训练集**和**测试集**。
训练集中的每个实例包含一个“目标值”(即类标签)和几个“属性”(即**特征或观察到的变量**)。SVM的目标是生成一个模型(基于训练数据)，该模型仅给出测试数据的属性来预测测试数据的目标值。

给定一个实例标签的训练集$(x_i,y_i),i=1,\dots,l; x_i\in R^n,y\in \{1,-1\}$

优化问题的形式![image-20210514192254114](C:\Users\chell\AppData\Roaming\Typora\typora-user-images\image-20210514192254114.png)

在这里，训练向量$x_i$被映射到一个更高维的空间利用函数$φ$。支持向量机找到一个边界最大的线性分离超平面

在这个高维空间中。C是误差项的惩罚参数

$K(x_i,x_j)≡φ(xi)^T φ(xj)$称为核函数。

以下是四个基本的核函数：

+ 线性：$K(X_i,X_j)=x_i ^Tx_j$
+ 多项式：$K(X_i,X_j)=(\gamma x_i ^Tx_j+r)^d,\gamma >0$
+ 径向基:$K(x_i , x_j ) = exp(−γ||x_i − x_j||^2 ), γ > 0.$
+ sigmoid:$K(x_i , x_j ) = tanh(γx_i^ T x_j + r)$

$γ、r、d$是核参数。

### 1.1实际例子

### 1.2过程设计

+ 将数据转换为SVM包的格式
+ 对数据进行简单的缩放
+ 考虑RBF核$K(x,y) = e^{−\gamma ||x−y||^2}$
+ 使用交叉验证找到最佳参数$C$和$γ$
+ 使用最佳参数$C$和$γ$训练整个训练集
+ 测试

接下来将在下面的部分中详细讨论这个过程

## 2.数据处理

### 2.1范畴特征

SVM要求每个数据实例被表示为一个实数的向量。
因此，如果有分类属性，我们首先要把它们转换成数字属性数据。
可以使用m个数字来表示m类属性。
m个数字中只有一个是1，其他都是0。

例如，一个三类的属性可以表示为(0,0,1), (0,1,0), 和(1,0,0)。
经验表明，如果一个属性的值的数量不是太大。这种编码方式可能比使用单个数字更稳定。

最佳参数可能会受到数据集大小的影响，但在实践中，从交叉验证中得到的参数已经适合整个训练集。但在实践中，从交叉验证中得到的参数已经适用于整个训练集。

### 2.2缩放

在应用SVM之前进行缩放是非常重要的。缩放的主要优点是避免大数值范围内的属性支配小数值范围内的属性。另一个优点是可以避免计算过程中的数字困难。
因为核值通常取决于特征向量的内积，例如线性核和多项式核，大的属性值可能会导致数值上的问题。 例如，线性核和多项式核，大的属性值可能会导致数字问题。例如：
> 建议线性缩放每个属性到[-1; +1]或[0; 1]的范围。

当然，也必须用同样的方法来扩展训练和测试数据。
例如，假设我们将训练数据的第一个属性从[-10; +10缩放]到[-1; +1]。如果测试数据的第一个属性位于[-11; +8]的范围内，则必须将测试数据缩放到[-1：1；+0：8]。**(附录B)**

## 3.模型选择

尽管在第1节中只提到了四个常见的内核，但必须决定首先尝试哪一个。然后选择惩罚参数C和内核参数的选择